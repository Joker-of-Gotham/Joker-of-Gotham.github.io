---
layout: post
title: "统计关系学习(Statistical relational learning)"
date: 2025-07-16
categories: [数学，逻辑学]
tags: [综述笔记]
published: true
mermaid: true
math: true
---

## 概率逻辑编程

统计关系学习（Statistical Relational Learning, SRL）是人工智能与机器学习的一个子领域，专注于既具备不确定性（可通过统计方法处理），又具有复杂关系结构的领域模型。通常，SRL 中开发的知识表示形式会使用一阶逻辑（的一部分）来以通用方式（普遍量化）描述领域中的关系特性，同时运用概率图模型（如贝叶斯网络或马尔可夫网络）来处理不确定性；有些方法还借鉴了归纳逻辑编程的技术。自 20 世纪 90 年代末以来，该领域取得了显著发展。


> **一阶逻辑(First-order logic)**  
> **一阶逻辑**，也称为谓词逻辑、谓词演算或量化逻辑，一阶逻辑使用非逻辑对象的量化变量，并允许使用包含变量的句子。  
> “一阶”一词区分了一阶逻辑与高阶逻辑，在高阶逻辑中，存在以谓词或函数为参数的谓词，或者允许对谓词、函数或两者进行量化。在一阶理论中，谓词通常与集合相关联。在解释的高阶理论中，谓词可能被解释为集合的集合。  
> 一阶逻辑是数学公理化形式化的标准，并在数学基础中得到研究。皮亚诺算术和策梅洛–弗兰克尔集合论分别是数论和集合论在一阶逻辑中的公理化。然而，没有任何一阶理论具有足够的力量来唯一描述具有无限域的结构，例如自然数或实数线。要完全描述这两种结构，即分类公理系统，可以在更强的逻辑中，如二阶逻辑中，获得这样的公理系统。  
> **进一步的，下面给出一阶逻辑及其组分的示例**  
> - 考虑两个句子“苏格拉底是一位哲学家”和“柏拉图是一位哲学家”。在命题逻辑中，这些句子本身被视为研究的个体，例如可以用变量 p 和 q 来表示。它们不被视为对论域中任何特定对象的谓词应用，而是被视为纯粹是陈述句，要么为真要么为假。然而，在一阶逻辑中，这两个句子可以被表述为某个特定个体或非逻辑对象具有某种属性的陈述。在这个例子中，两个句子碰巧具有对某个个体$\text{isPhil}(x)$ 。在第一个句子中，变量 x 的值为“苏格拉底”，在第二个句子中为“柏拉图”。由于能够谈论非逻辑个体以及原始的逻辑连接词，一阶逻辑包含了命题逻辑。  
> - 一个公式如“x 是一个哲学家”的真值取决于 x 所表示的对象以及谓词“是一个哲学家”的解释。因此，“x 是一个哲学家”本身没有确定的真或假值，类似于一个句子片段。 [8] 谓词之间的关系可以使用逻辑连接词来陈述。例如，一阶公式“如果 x 是一个哲学家，那么 x 是一个学者”是一个条件语句，其假设为“x 是一个哲学家”，结论为“x 是一个学者”，这同样需要指定 x 才能具有确定的真值。  
> - 量词可以应用于公式中的变量。前一个公式中的变量 x 可以被全称量化，例如，用一阶句子“对于每一个 x，如果 x 是一个哲学家，那么 x 是一个学者”。这个句子中的全称量词“对于每一个”表达了“如果 x 是一个哲学家，那么 x 是一个学者”这一主张对所有 x 的选择都成立的思想。  
> - 句子"对于每一个 x，如果 x 是哲学家，那么 x 是学者"的否定在逻辑上等价于句子"存在某个 x，使得 x 是哲学家且 x 不是学者"。存在量词"存在"表达了"x 是哲学家且 x 不是学者"这一命题对于某些 x 的选择成立的思想。  
> - 谓词"是哲学家"和"是学者"各自取一个变量。通常，谓词可以取多个变量。在一阶句子"Socrates 是 Plato 的老师"中，谓词"是...的老师"取两个变量。
{: .prompt-info }

**统计关系学习的典型任务包括**：

- 集体分类，即根据对象的属性及其关系（同时）预测多个对象的类别
- 链接预测，即预测两个或多个对象之间是否存在关联
- 基于链接的聚类，即将相似对象分组，其中相似性根据对象的链接确定，以及相关的协同过滤任务，即过滤与实体相关的信息（其中，如果已知某信息与相似实体相关，则认为该信息与该实体相关）
- 对象识别/实体解析/记录链接，即识别两个或多个独立数据库/数据集中的等价条目
- 社交网络建模

**需要进一步拓展的内容包括**：

- 关系马尔可夫网络与马尔可夫逻辑网络
- 关系贝叶斯网络与贝叶斯逻辑网络
- 概率关系模型(PRMs)与概率关系图
- 概率软逻辑与概率逻辑程序

### 关系马尔可夫网络与马尔可夫逻辑网络

#### [关系马尔可夫网络](http://www.robotics.stanford.edu/~koller/Papers/Taskar+al:SRL07.pdf)

框架基础：一个基于无向图的概率建模框架

关系马尔可夫网络可能解决的问题：

- **实现文档的关联分类**：考虑一个我们想要使用一组标签进行分类的超文本文档集合。最直观的方法是使用词袋模型。然而，这种方法完全忽略了超文本的丰富结构。一个文档会链接到其他文档，通常表明它们的主题相关；每个文档还具有内部结构。在分类文档集合时，这些线索是重要的，可能有助于我们实现更高的分类准确率。因此，我们不是单独分类每个文档，而是希望提供一种集体分类的形式，即在同时决定所有实体的类别标签，从而可以明确利用相关实体标签之间的相关性。
- **预测实体间关联关系**：一个挑战来自于预测哪些实体与哪些其他实体相关联，以及这些关系的类型。例如，在一个包含一组超链接大学网页的数据集中，我们不仅可能想要预测哪些页面属于教授，哪些属于学生，还可能想要预测哪些教授是哪些学生的导师。在某些情况下，关系的存在将通过页面之间的超链接来预测，我们只需决定该链接是否反映了导师-学生关系。在其他情况下，我们可能需要从间接证据中推断链接的存在，例如大量合著的论文。

##### 关系马尔可夫网络中的关系分类

**模式定义一组实体类型**：$E=\{ E_1,\cdots,E_n \}$，其具有如下三组属性

- 内容属性(content attributes)：$E.\bf{X}$
- 标签属性(label attributes)：$E.\bf{Y}$
- 引用属性(reference attributes)：$E.\bf{R}$，其包含唯一键属性$E.\bf{K}$用于识别每个实体；其他类型的实体指向单一类型实体$E=Range(E.\bf{R})$，其值在$Domain(E.\bf{K})$中

模式E的实例I指定了每个实体类型$E∈\epsilon$的实体集合$I(E)$，示例$I$同样包括${I.\bf{X}},{I,\bf{Y}},{I.\bf{R}}$，这些属性的值用$I.x,I.y,I.r$表示；其中$I.r$被称为**实例骨架(nstantiation skeleton / instantiation graph)**，指定实体(节点)集合及其引用属性(边)
> **案例**  
> 假设实体类型集合包括WebPage、Author，那么对应的实例化 I 中会有：I(WebPage)：如 {page1, page2, page3}，I(Author)：如 {alice, bob}，作者 alice 的属性，比如姓名、学科领域等，可设作 I.x(alice)、I.y(alice)、I.r(alice)（如 co-author 的链接关系）  
> 每个实体拥有属性包括网页 page1 的内容（X），标签（Y），及链接（R）：  
> - $I.x(page1)$ = 一篇网页的单词内容  
> - $I.y(page1)$ = 分类标签（如“新闻”）  
> - $I.r(page1)$ = 链向的其它网页（如 {page2, page3}）  
{: .prompt-example }

同时，在概率关系模型中也需要把“链接”也当作模型里的一等公民，引入结构不确定性（Structural Uncertainty）以便做链接预测（Link Prediction）。假设连接$l$表示实体$\{ o_i,o_j \}$之间的连接，则$l.Exists$表示该链接存在，反之表示不存在；引入结构不确定性的模型可以预测链接是否应存在，并将这种结构作为条件用来提升属性预测准确率，其是建模的核心策略之一。

##### 关系马尔可夫网络的图结构和子图模板

利用概率关系模型(PRMs)对实体进行建模，可以诱导出大型贝叶斯网络，在实体属性间建立依赖。

例如在$Doc.Label$和$Doc.HasWord$之间建立链接，则二者间会关联一个条件概率分布$P(Doc.HasWord\| Doc.Label)$。

同时，可以将关系语言和概率图模型结合为建模关系图，该方法具有灵活和关系易展现等优势。

一些完善子图模板的方式：
- 可以引入更丰富的子图模板，如相似性模板，即共享某种基于土属性的对象更有可能具有相同标签
- 可以引入对传递模式的研究，即存在A-B链接和B-C链接会增加(或减少)A-C链接的可能性，这种三元依赖只能用无向图建模，并通过 clique 直接表达

但是要实现上述内容，概率依赖图因其必须是定向无环图的约束难以实现，而使用无向马尔科夫网络作为网络则良好解决了该问题

##### 关系马尔可夫网络的定义与设置

**第一阶段：原始概率定义**

记呈现出的马尔可夫网络为图$G$，其节点集则为$V$，节点集的真子集被称为团$V_{c}$，团内$V_{i},V_{j}$间有边相连。

令$G=(V,E)$为包含团簇$C(G)$的无向图，每个$c \in C(G)$都与一个节点集$V$和一个团势$\phi(V)$相关联，$\phi(V)$在$V$的联合域中非负，$\phi=\{\phi(V)\}$，分布：
$$P(v)=\frac{1}{Z} \Pi_{c \in C(G)}\phi_{c}({\bf{v_c}})$$

其中规范化常数:
$$Z=\sum_{v'}\Pi_{c \in C(G)}\phi_{c}({\bf{v'_c}})$$

每个势函数$\phi_c$可视为一个“不归一化”的表格，衡量给定团内各变量赋值组合的兼容性，表达式为:
$$\phi_c(v_c)=exp\{ \sum\limits_{i}w_i f_i({\bf{v_c}}) \}=exp\{{\bf{w_c \cdot f_c{(v_c)}}}\}$$

其联合分布写作：
$$logP({\bf{v}})=\sum\limits_{c}{\bf{w_c \cdot f_c(v_c)}}-logZ={\bf{w \cdot f(v)}}-logZ$$

其中各参量的含义为：

- **$\bf{f}$**：逻辑或行为函数，指示特定局部模式是否发生
- **$\bf{w}$**：表示该模式对概率的促进或抑制程度

**第二阶段：条件概率定义**

设$X$为条件随机变量，$Y$为目标(标签)随机变量，条件马尔可夫网络定义了条件分布：
$$P(y|x)=\frac{1}{Z(x)}\Pi_{c \in C(G)}\phi({\bf{x_c,y'_c}})$$

其中：

$$Z(x)=\sum_{\bf{y'}}\phi(\bf{x_c,y'_c})$$

与传统马尔可夫网络建模联合分布 $P(x,y)$ 不同，条件马尔可夫网络直接建模的是 $P(y∣x)$，这种判别式建模只关注标签 $Y$ 在观测到 $X$ 情况下的分布，不试图生成 $X$，适用于分类任务且通常具有更好性能

**第三阶段：结构化查询定义**

定义关系团模板$C=(F,W,S)$，其中：

- **F(From)**：一组实体变量$\{ F_i \}$，每个带类型$E(F_i)$
- **W(where)**：一个布尔条件，由比较实体键($.R$ 属性)构成，筛选出“真实相连”的实体组合
- **S(Select)**：从这些实体中选出的属性集合(内容$X$或标签$Y$)，构成团内的随机变量

进一步的，经过下面几个步骤，可从关系团模板到实例化团：

- 实体交叉：$I(F)=I(E(F_1)) \times \cdots \times I(E(F_n))$
- 筛选：只保留满足W条件的实体元组$f=(f_1,\cdots,f_n)$，表示为$W(F.R)$作为若干等式或不等式的布尔集合
- 投影：对每个保留的元组，取出在$S$中指定的属性值，形成一个团的实例$c=f.S=\{ f_i,A:A \in S \}$
- 集合化：所有这样的$c$构成改模板在$I$上的团集合$C(I)$

> 例如下述代码案例为共同来源三元模板：  
> ```sql  
> FROM Doc AS doc1, Doc AS doc2, Link AS l1, Link AS l2  
> WHERE l1.From = l2.From  
>  AND l1.To   = doc1.Key  
>  AND l2.To   = doc2.Key  
>  AND doc1.Key <> doc2.Key  
> ```  
> 其对应的$W$为：$(l_1.From=l_2.From) \land (l_1.To=doc_1.Key) \land (l_2.To=doc_2.Key) \land (doc_1.Key \neq doc_2.Key)$

**第四阶段：RMN完整的计算构造与实例化**

一个 **关系马尔可夫网络 (RMN)** $M = (\mathcal{C}, \Phi)$ 包含：

- $\mathcal{C}$：一组**关系团模板**。  
- $\Phi = \{\phi_C\}_{C \in \mathcal{C}}$：每个模板对应的**团势函数**。

给定一个实例化 $I$（包含内容属性 $I.x$、关系骨架 $I.r$ 和待预测标签 $I.y$），RMN 定义条件分布：

$$
P\bigl(I.y \mid I.x, I.r\bigr)
\;=\;
\frac{1}{Z\bigl(I.x, I.r\bigr)}
\;\prod_{C\in\mathcal{C}}
\;\prod_{c\in C(I)}
\phi_C\bigl(I.x_c, I.y_c\bigr),
$$

其中**归一化常数**（分区函数）为：

$$
Z\bigl(I.x, I.r\bigr)=
\sum_{I.y'}
\;\prod_{C\in\mathcal{C}}
\;\prod_{c\in C(I)}
\phi_C\bigl(I.x_c, I.y'_c\bigr).
$$

若采用**对数线性**参数化$\displaystyle \phi_C(v_c) = \exp\{\,w_C \cdot f_C(v_c)\}$，则可写为：

$$
\log P\bigl(I.y \mid I.x, I.r\bigr)= 
\sum_{C\in\mathcal{C}}
\sum_{c\in C(I)}
w_C \!\cdot\! f_C\bigl(I.x_c, I.y_c\bigr)
\;-\;
\log Z\bigl(I.x, I.r\bigr).
$$

定义**实例化特征**：

$$
f_C\bigl(I.x, I.y, I.r\bigr)=
\sum_{c\in C(I)}
f_C\bigl(I.x_c, I.y_c\bigr),
$$

记 $w$ 和 $f$ 为所有 $w_C$ 与 $f_C$ 的拼接向量，则有：

$$
\log P\bigl(I.y \mid I.x, I.r\bigr)= 
w \!\cdot\! f\bigl(I.x, I.y, I.r\bigr)
\;-\;
\log Z\bigl(I.x, I.r\bigr).
$$

其中一些关键参量的定义包括：

- **模板集合$\mathcal{C}$**：提前定义好“在哪些局部子图上插入潜势”，例如“每条链接上的两个文档标签”“同一来源的三元组”等
- **实例化团集合$C(I)$**：对每个模板$C$，用前面定义的关系查询在骨架$I.r$上找到所有匹配的子图，得到具体的团$c$
- **特征函数$f_C$**：关系马尔可夫网络中用来量化“局部配置偏好”的基本构件，其将团中每一种可能的变量取值组合$v_C=(v_{i1},\cdots,v_{ik})$映射为一个实数

> **实际案例**  
> 定义一个检测“链接页标签相同”模式的团模板  
> ```sql  
> SELECT doc1.Category, doc2.Category  
> FROM   Doc AS doc1, Doc AS doc2, Link AS link  
> WHERE  link.From = doc1.Key  
>   AND  link.To   = doc2.Key  
> ```  
> 团模板$C$捕获每条超链接对应的一对文档标签，团变量 $V_C = { Y_1, Y_2 }$，其中$Y_1 = doc_1.Category，Y_2 = doc_2.Category$  
> 然后可以定义两个特征函数：$f_C^{same}:\{ 标签 \}^2 \to \{ 0,1 \}$，即当$y_1=y_2$时特征取1否则取0，使模型会偏好将相连页面标为同一类别；$f_C^{sim}:\{ 标签 \}^2 \to R$，写作$f_C^{sim}=|w_1 \cap w_2|$，其中$w_1$为$doc_1$中单词集合，$w_2$为$doc_2$中单词集合$f_C^{sim}$返回它们交集的大小，使共享单词越多时特征值越大  
> 进而利用潜势函数进行计算
{: .prompt-example }

**第五阶段：基于关系马尔可夫网络的学习模型**

假设已知关系团模板集合 $\mathcal{C}$，我们需要估计对应的潜势函数参数（或特征权重）$w$。给定训练集 $D$（其中内容属性 $I.x$ 和标签 $I.y$ 都已观测），我们的目标是：

- **定义目标函数**  
   - **极大似然（ML）**：最大化标签在给定内容和结构下的联合概率  
     $$
       L_{\rm ML}(w)
       = \sum_{d\in D}\log P_w(y_d\mid x_d)
       = \sum_{d}\bigl[w\!\cdot\!f(x_d,y_d)-\log Z(x_d)\bigr].
     $$
   - **最大后验（MAP）**：加入零均值高斯先验 $p(w_i)\propto\exp(-w_i^2/2\sigma^2)$，防止过拟合  
     $$
       L_{\rm MAP}(w)
       = \sum_{d}\bigl[w\!\cdot\!f(x_d,y_d)-\log Z(x_d)\bigr]
         - \frac{\|w\|^2}{2\sigma^2} + C.
     $$

- **计算梯度**
   - 对于**平坦(i.i.d.)**情况：
     $$
       \nabla L(w)
       = \sum_{d\in D}\Bigl[f(x_d,y_d)\;-\;\mathbb{E}_{P_w}[\,f(x_d,Y_d)\,]\Bigr]
       \;-\;\frac{w}{\sigma^2},
     $$
     其中
     $$
       \mathbb{E}_{P_w}[f(x_d,Y)]
       = \sum_{y'} f(x_d,y')\,P_w(y'\mid x_d).
     $$
   - 对于**关系**情况（单个实例化 $I$）：
     $$
       \nabla L(w)
       = f(I.y,I.x,I.r)\;-\;\mathbb{E}_{P_w}\bigl[f(I.Y,I.x,I.r)\bigr]
         \;-\;\frac{w}{\sigma^2},
     $$
     其中
     $$
       \mathbb{E}_{P_w}[f(I.Y,I.x,I.r)]
       = \sum_{I.y'} f(I.y',I.x,I.r)\,P_w(I.y'\mid I.x,I.r).
     $$

- **优化方法**  
   - 对数‐线性目标函数是**凹**函数，可用共轭梯度（Conjugate Gradient）或 L‑BFGS 等高效数值优化方法求解。  
   - 对于 CRF 和 RMN，经验表明 L‑BFGS 收敛更快。

- **计算期望的难点**  
   - 平坦模型中，各训练样本独立，期望可逐实例分开计算；  
   - 关系模型中，所有标签相关，需要在展开的巨大马尔可夫网络上运行**推断**（如 Belief Propagation），才能估计联合期望。

在马尔可夫网络中的推断则可以采用如下流程

- **目标**：计算给定 $x$ 后，各标签变量的后验边缘分布。  
- **方法**：  
  - 对于低树宽图可用精确算法；  
  - 对于超大稠密图（如超文本分类），采用 **Belief Propagation (BP)** 进行近似推断：  
    - 在任意图上迭代消息传递，经验上即使有循环也往往收敛且结果准确。  
    - BP 每次迭代更新节点对邻居的“信念”，直至收敛后读取边缘概率。

> **流程小结**  
> 1. 定义团模板 $\mathcal{C}$  
> 2. 构造对数‐线性目标 $L(w)$（含先验）  
> 3. 重复：  
>    - 运行 BP 估计 $\mathbb{E}_{P_w}[f]$  
>    - 用梯度方法更新 $w$  
> 4. 直到收敛  
{: .prompt-flow }

这样即可完成 RMN 的判别式 MAP 学习。