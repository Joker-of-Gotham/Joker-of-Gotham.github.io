---
layout: post
title: "机器学习与算法交易(三): 机器学习与复杂因子分析交易"
date: 2025-08-11
categories: [人工智能, 机器学习, 金融分析]
tags: [综述笔记, 金融量化]
published: true
mermaid: true
math: true
toc: true
---

# 机器学习流程

## 为任务匹配算法

不同算法的假设空间⼤⼩差异显著。⼀⽅⾯，这种限制使得成功的搜索成为可能；另⼀⽅⾯，它也意味着⼀种归纳偏⻅，当算法从训练样本泛化到新数据时，可能会导致性能不佳。因此，关键的挑战在于如何选择⼀个模型，其假设空间既要⼤到⾜以包含学习问题的解决⽅案，⼜要⼩到⾜以在给定训练数据规模的情况下确保可靠的学习和泛化。有了信息量更⼤的数据，拥有更⼤假设空间的模型成功的机会也更⼤。

## 机器学习的工作流程

1. 界定问题，确定目标指标，定义成功标准
2. 获取、清洗并验证数据
3. 理解你的数据并生成信息丰富的特征
4. 选择一个或多个适合个性化数据的机器学习方法
5. 训练、测试并调整模型、
6. 使用训练好的模型来解决最初的问题

### 构建问题：从目标到目标

任何机器学习项⽬的起点都是它最终旨在解决的⽤例。有时，这个⽬标是为了识别变量之间的关联甚⾄因果关系⽽进⾏统计推断。然⽽，最常⻅的⽬标是预测结果以产⽣交易信号。我们根据输出的性质来区分预测任务：连续的输出变量构成回归问题，分类变量意味着分类问题，⽽有序分类变量的特殊情况则代表排序问题。

你通常可以⽤不同的⽅式来构建⼀个给定的问题。⼿头的任务可能是如何有效地结合多个阿尔法因⼦。你可以将这个任务构建成⼀个旨在预测回报的回归问题，⼀个旨在预测未来价格⾛势⽅向的⼆元分类问题，或者⼀个旨在将股票分配到不同表现类别（如回报率五分位数）的多类别问题。

### 预测与推断

#### 因果推断：相关性不等于因果性

因果推断旨在识别某些输⼊值意味着某些输出值的关系。关于两个或多个变量之间关系的统计推断会产⽣相关性的度量。只有在满⾜其他⼏个条件时，相关性才能被解释为因果关系：例如，当排除了其他解释或反向因果关系时。

要满⾜这些条件，需要⼀个实验环境，其中所有相关的⽬标变量都可以被完全控制，以分离出因果关系。但是这些条件很少能得到满⾜，因此推断性结论需要谨慎对待。这同样适⽤于预测模型的性能，因为预测模型也依赖于特征和输出之间的统计关联，⽽这种关联可能会随着模型之外的其他因素⽽改变。

#### 回归：常⽤的损失函数和误差指标

回归问题旨在预测⼀个连续变量。均⽅根误差（RMSE）是最常⽤的损失函数和误差指标，这不仅因为它可微。该损失函数是对称的，但在计算中，较⼤的误差权重更⾼。使⽤平⽅根的好处在于，我们可以⽤⽬标变量的单位来衡量误差。当⽬标呈指数级增⻓时，适合使⽤对数误差均⽅根（RMSLE）。绝对误差均值（MAE）和绝对误差中位数（MedAE）是对称的，但不会给较⼤的误差赋予更多权重；MedAE 对异常值具有稳健性。

<div style="text-align: center;">
<img src="/assets/images/LLM学习/机器学习与金融量化/六种损失函数.png" alt="描述文字" width="880" height="510">
</div>

#### 分类：理解混淆矩阵、ROC与F1曲线

**混淆矩阵**即一个四元标签组：[假阳性，假阴性，真阳性，真阴性]

受试者⼯作特征（ROC）曲线使我们能够根据分类器的性能对其进⾏可视化、⽐较和选择。它计算了将所有预测得分⽤作阈值以产⽣类别预测时，所得到的真阳性率（TPR）和假阳性率（FPR）对。它将这些点对在⼀个单位边⻓的正⽅形内进⾏可视化。随机预测（加权以考虑类别不平衡）平均会产⽣相等的 TPR 和 FPR，这些点会出现在对⻆线上，这就成了基准情况。由于表现不佳的分类器可以通过重新标记预测结果来获益，因此这个基准也成了最低标准。

**曲线下⾯积（AUC）**定义为 ROC 图下⽅的⾯积，其值在 0.5 到最⼤值 1 之间变化。它是⼀个汇总性指标，衡量分类器的得分在根据类别归属对数据点进⾏排序⽅⾯的表现。更具体地说，分类器的 AUC 有⼀个重要的统计特性，即它代表了分类器将⼀个随机选择的正例排在⼀个随机选择的负例之前的概率，这等同于 Wilcoxon 秩和检验（Fawcett 2006）。此外，AUC 还有⼀个优点，即它对类别不平衡不敏感。

**召回率（Recall）**衡量的是，在给定阈值下，分类器预测为正例的样本占所有实际正例样本的⽐例。这个概念源于信息检索领域，⽤于衡量搜索引擎成功识别出的相关⽂档所占的份额。相⽐之下，精确率（Precision）衡量的是，在所有被预测为正例的样本中，预测正确的⽐例。召回率通常会随着阈值的降低⽽提⾼，但精确率可能会随之下降。精确率-召回率曲线（Precision-recall curves）将所有可⾏的组合可视化，以便在“漏掉⼤量相关案例”和“产⽣低质量预测”的成本与收益之间进⾏权衡，从⽽优化阈值。**F1 分数（F1 score）**是给定阈值下精确率和召回率的调和平均数，可⽤于从数值上优化阈值，同时还能考虑到这两个指标应占的相对权重。

### 特征分析与提取

**系统性的探索性分析**也是成功预测模型中通常最重要的单⼀因素的基础：**特征⼯程**。特征⼯程旨在提取数据中包含的信息，⽽这些信息在原始形式下不⼀定能被算法直接获取。特征⼯程得益于领域专业知识、统计学和信息论的应⽤，以及创造⼒。

同时**也可以使用信息论评估特征**，特征与结果之间的互信息（MI）是衡量这两个变量之间相互依赖性的指标。它将相关性的概念扩展到了⾮线性关系。更具体地说，它量化了通过⼀个随机变量获得的关于另⼀个随机变量的信息。

$$I(X,Y)=\int_{X} \int_{Y} p(x,y) log(\frac{p(x,y)}{p(x)p(y)})$$

### 机器学习的算法选择

#### 偏差-方差均衡与学习曲线

在优化机器学习算法的过程中，需要考虑偏差-方差权衡，即不能欠拟合，也需要尽可能避免过拟合。⾼偏差模型⽆论在样本内还是样本外，都会有较⾼但相似的训练误差。⽽过拟合模型的训练误差会⾮常低，但测试误差会⾼得多。

#### 如何用交叉验证选择模型

交叉验证（CV）是⼀种常⽤的模型选择策略。其主要思想是将数据进⾏⼀次或多次拆分。这样⼀来，每个数据⼦集都有⼀次机会被⽤作验证集，⽽其余部分则⽤作训练集：⼀部分数据（训练样本）⽤于训练算法，剩余部分（验证样本）则⽤于评估算法的预测性能。然后，交叉验证会选择估计误差或⻛险最⼩的算法。但交叉验证的⼀个关键假设是数据独⽴同分布（IID）。

<div style="text-align: center;">
<img src="/assets/images/LLM学习/机器学习与金融量化/三次划分法.png" alt="描述文字" width="880" height="430">
</div>

#### 验证曲线：绘制超参数的影响

验证曲线将单个超参数对模型交叉验证性能的影响可视化。这有助于确定模型对于给定数据集是⽋拟合还是过拟合。

#### 学习曲线：诊断偏差-⽅差权衡

学习曲线有助于确定模型的交叉验证性能是否会因额外数据⽽受益，以及预测误差是由偏差还是⽅差主导。如果训练得分和交叉验证得分趋于收敛，那么更多的数据不太可能提升模型性能。此时，重要的是评估模型性能是否达到由⼈类基准所确定的预期。如果未达到预期，那么您应该修改模型的超参数设置以更好地捕捉特征与结果之间的关系，或者选择另⼀种具有更⾼复杂性捕捉能⼒的算法。