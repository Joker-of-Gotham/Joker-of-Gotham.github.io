---
layout: post
title: "机器学习与算法交易(三): 机器学习与因子分析交易流程"
date: 2025-08-11
categories: [人工智能, 机器学习, 金融分析]
tags: [综述笔记, 金融量化]
published: true
mermaid: true
math: true
toc: true
---

# 机器学习流程

## 为任务匹配算法

不同算法的假设空间⼤⼩差异显著。⼀⽅⾯，这种限制使得成功的搜索成为可能；另⼀⽅⾯，它也意味着⼀种归纳偏⻅，当算法从训练样本泛化到新数据时，可能会导致性能不佳。因此，关键的挑战在于如何选择⼀个模型，其假设空间既要⼤到⾜以包含学习问题的解决⽅案，⼜要⼩到⾜以在给定训练数据规模的情况下确保可靠的学习和泛化。有了信息量更⼤的数据，拥有更⼤假设空间的模型成功的机会也更⼤。

## 机器学习的工作流程

1. 界定问题，确定目标指标，定义成功标准
2. 获取、清洗并验证数据
3. 理解你的数据并生成信息丰富的特征
4. 选择一个或多个适合个性化数据的机器学习方法
5. 训练、测试并调整模型
6. 使用训练好的模型来解决最初的问题

### 构建问题：从目标到目标

任何机器学习项⽬的起点都是它最终旨在解决的⽤例。有时，这个⽬标是为了识别变量之间的关联甚⾄因果关系⽽进⾏统计推断。然⽽，最常⻅的⽬标是预测结果以产⽣交易信号。我们根据输出的性质来区分预测任务：连续的输出变量构成回归问题，分类变量意味着分类问题，⽽有序分类变量的特殊情况则代表排序问题。

你通常可以⽤不同的⽅式来构建⼀个给定的问题。⼿头的任务可能是如何有效地结合多个阿尔法因⼦。你可以将这个任务构建成⼀个旨在预测回报的回归问题，⼀个旨在预测未来价格⾛势⽅向的⼆元分类问题，或者⼀个旨在将股票分配到不同表现类别（如回报率五分位数）的多类别问题。

### 预测与推断

#### 因果推断：相关性不等于因果性

因果推断旨在识别某些输⼊值意味着某些输出值的关系。关于两个或多个变量之间关系的统计推断会产⽣相关性的度量。只有在满⾜其他⼏个条件时，相关性才能被解释为因果关系：例如，当排除了其他解释或反向因果关系时。

要满⾜这些条件，需要⼀个实验环境，其中所有相关的⽬标变量都可以被完全控制，以分离出因果关系。但是这些条件很少能得到满⾜，因此推断性结论需要谨慎对待。这同样适⽤于预测模型的性能，因为预测模型也依赖于特征和输出之间的统计关联，⽽这种关联可能会随着模型之外的其他因素⽽改变。

#### 回归：常⽤的损失函数和误差指标

回归问题旨在预测⼀个连续变量。均⽅根误差（RMSE）是最常⽤的损失函数和误差指标，这不仅因为它可微。该损失函数是对称的，但在计算中，较⼤的误差权重更⾼。使⽤平⽅根的好处在于，我们可以⽤⽬标变量的单位来衡量误差。当⽬标呈指数级增⻓时，适合使⽤对数误差均⽅根（RMSLE）。绝对误差均值（MAE）和绝对误差中位数（MedAE）是对称的，但不会给较⼤的误差赋予更多权重；MedAE 对异常值具有稳健性。

<div style="text-align: center;">
<img src="/assets/images/LLM学习/机器学习与金融量化/六种损失函数.png" alt="描述文字" width="880" height="510">
</div>

#### 分类：理解混淆矩阵、ROC与F1曲线

**混淆矩阵**即一个四元标签组：[假阳性，假阴性，真阳性，真阴性]

受试者⼯作特征（ROC）曲线使我们能够根据分类器的性能对其进⾏可视化、⽐较和选择。它计算了将所有预测得分⽤作阈值以产⽣类别预测时，所得到的真阳性率（TPR）和假阳性率（FPR）对。它将这些点对在⼀个单位边⻓的正⽅形内进⾏可视化。随机预测（加权以考虑类别不平衡）平均会产⽣相等的 TPR 和 FPR，这些点会出现在对⻆线上，这就成了基准情况。由于表现不佳的分类器可以通过重新标记预测结果来获益，因此这个基准也成了最低标准。

**曲线下⾯积（AUC）**定义为 ROC 图下⽅的⾯积，其值在 0.5 到最⼤值 1 之间变化。它是⼀个汇总性指标，衡量分类器的得分在根据类别归属对数据点进⾏排序⽅⾯的表现。更具体地说，分类器的 AUC 有⼀个重要的统计特性，即它代表了分类器将⼀个随机选择的正例排在⼀个随机选择的负例之前的概率，这等同于 Wilcoxon 秩和检验（Fawcett 2006）。此外，AUC 还有⼀个优点，即它对类别不平衡不敏感。

**召回率（Recall）**衡量的是，在给定阈值下，分类器预测为正例的样本占所有实际正例样本的⽐例。这个概念源于信息检索领域，⽤于衡量搜索引擎成功识别出的相关⽂档所占的份额。相⽐之下，精确率（Precision）衡量的是，在所有被预测为正例的样本中，预测正确的⽐例。召回率通常会随着阈值的降低⽽提⾼，但精确率可能会随之下降。精确率-召回率曲线（Precision-recall curves）将所有可⾏的组合可视化，以便在“漏掉⼤量相关案例”和“产⽣低质量预测”的成本与收益之间进⾏权衡，从⽽优化阈值。**F1 分数（F1 score）**是给定阈值下精确率和召回率的调和平均数，可⽤于从数值上优化阈值，同时还能考虑到这两个指标应占的相对权重。

### 特征分析与提取

**系统性的探索性分析**也是成功预测模型中通常最重要的单⼀因素的基础：**特征⼯程**。特征⼯程旨在提取数据中包含的信息，⽽这些信息在原始形式下不⼀定能被算法直接获取。特征⼯程得益于领域专业知识、统计学和信息论的应⽤，以及创造⼒。

同时**也可以使用信息论评估特征**，特征与结果之间的互信息（MI）是衡量这两个变量之间相互依赖性的指标。它将相关性的概念扩展到了⾮线性关系。更具体地说，它量化了通过⼀个随机变量获得的关于另⼀个随机变量的信息。

$$I(X,Y)=\int_{X} \int_{Y} p(x,y) log(\frac{p(x,y)}{p(x)p(y)})$$

### 机器学习的算法选择

#### 偏差-方差均衡与学习曲线

在优化机器学习算法的过程中，需要考虑偏差-方差权衡，即不能欠拟合，也需要尽可能避免过拟合。⾼偏差模型⽆论在样本内还是样本外，都会有较⾼但相似的训练误差。⽽过拟合模型的训练误差会⾮常低，但测试误差会⾼得多。

#### 如何用交叉验证选择模型

交叉验证（CV）是⼀种常⽤的模型选择策略。其主要思想是将数据进⾏⼀次或多次拆分。这样⼀来，每个数据⼦集都有⼀次机会被⽤作验证集，⽽其余部分则⽤作训练集：⼀部分数据（训练样本）⽤于训练算法，剩余部分（验证样本）则⽤于评估算法的预测性能。然后，交叉验证会选择估计误差或⻛险最⼩的算法。但交叉验证的⼀个关键假设是数据独⽴同分布（IID）。

<div style="text-align: center;">
<img src="/assets/images/LLM学习/机器学习与金融量化/三次划分法.png" alt="描述文字" width="880" height="430">
</div>

#### 验证曲线：绘制超参数的影响

验证曲线将单个超参数对模型交叉验证性能的影响可视化。这有助于确定模型对于给定数据集是⽋拟合还是过拟合。

#### 学习曲线：诊断偏差-⽅差权衡

学习曲线有助于确定模型的交叉验证性能是否会因额外数据⽽受益，以及预测误差是由偏差还是⽅差主导。如果训练得分和交叉验证得分趋于收敛，那么更多的数据不太可能提升模型性能。此时，重要的是评估模型性能是否达到由⼈类基准所确定的预期。如果未达到预期，那么您应该修改模型的超参数设置以更好地捕捉特征与结果之间的关系，或者选择另⼀种具有更⾼复杂性捕捉能⼒的算法。

# 线性模型：从风险因子到收益预测

## 从推断到预测

**1. 线性回归模型的基本假设**

- **线性关系假设**：输出变量$y$是输入变量的线性组合再加上一个随机误差项 $\varepsilon$。
- **随机误差的意义**：误差允许每个观测值与理想的线性关系有偏离，原因可能包括：
    - 重要变量缺失
    - 测量误差
    - 数据收集问题
- **误差的统计假设（基线模型）**：
    1. 误差服从相同分布（方差一致）
    2. 各观测的误差相互独立
    3. 独立同分布（i.i.d.）意味着误差的协方差矩阵为常数 $\sigma^2$ 乘以单位矩阵 III

这些假设保证了 OLS（普通最小二乘）不仅是无偏估计，还在所有线性无偏估计中具有最小方差（有效性）。

**2. 现实中的挑战**

在实际金融数据中，特别是 **面板数据**（同一资产在不同时间的重复观测），上述假设常常被破坏：

- 时间维度上存在相关性（序列相关）
- 横截面维度上存在相关性（不同资产之间相关）
- 两者同时存在

当误差不再是单位矩阵的倍数时，需要更复杂的模型假设和估计方法。

**3. 解决方法**

3.1 改进线性模型的估计方法

- 针对违背 i.i.d. 假设的情况，使用更复杂的误差协方差结构（如 Newey-West 标准误）来获得稳健估计。

3.2 有偏估计 + 降低方差（收缩方法）

- 思路：引入**正则化惩罚项**，限制系数的大小，从而降低模型复杂度。
- 原理：惩罚项与系数的绝对值大小正相关，系数越大，模型对输入的波动反应越强，复杂度也越高。
- 优势：如果正则化强度（惩罚系数）选择得当，从**偏差-方差权衡**的角度可以得到更优的预测性能。
- 常见方法：Lasso、Ridge、Elastic Net 等。

## 基准模型：多元线性回归

最基础的多元线性回归模型可以用下述公式表示：

$$\bf{y}=\bf{X} \boldsymbol{\beta} + \boldsymbol{\epsilon}$$

训练时则可以用多种方法进行训练：普通最小二乘法，最大似然估计和随机梯度下降法。

### 高斯-马尔可夫定理

⾼斯-⻢尔可夫定理（GMT）定义了普通最⼩⼆乘法（OLS）要对模型参数产⽣⽆偏估计所需满⾜的假设，并确保这些估计在所有针对横截⾯数据的线性模型中具有最低的标准误。

该定理的核心内容为：

$$\begin{aligned} & 对于给定的多元回归模型： y_{i}=\sum\limits_{k=1}\beta_{k}x_{ik}+\beta_{0}+\epsilon_{i}  \\ & 假设条件包括：  \\ &  1.线性关系成立：模型在参数上线性 \\ & 2.随机抽样：(x_{i1},\cdots,x_{ik},y_{i})来自总体的随机样本 \\ & 3. 无完全共线性：解释变量间不存在精确的线性依赖 \\ & 4. 零条件均值：\mathbb{E}[\epsilon_{i} \| {\bf{X}}_{i}]=0 \to 不存在与任何解释变量相关的遗漏变量 \\ & 5. 同方差性：Var(\epsilon_{i} \| {\bf{X}}_{i})=\sigma^{2} \to 误差方差对所有观测恒定 \end{aligned}$$

该定理可以这样简单理解：第一点反映了输入输出间整体呈现可信的线性关系，第二点反映了样本的覆盖度，第三点反映了输入输出的随机性与可信度，第四点反映了模型囊括了所有输入变量，第五点反映了推断的准确性。

即使正态性假设不成⽴，在正态性假设下使⽤的检验统计量也近似有效。更具体地说，在满⾜⾼斯-⻢尔可夫定理的 1-5 条假设时，检验统计量的以下分布特征近似成⽴；⽽在满⾜正态性假设时，这些特征则精确成⽴：

- 参数服从多元正态分布：$\hat{\beta} \sim N(\beta,({\bf{X}^{T}X})^{-1}\sigma)$
- 满足高斯-马尔可夫定理时参数估计无偏，为$\hat{\sigma}=\frac{1}{N-p-1}\sum\limits_{i=1}^{N}(y_{i}-\hat{y}_{i})^{2}$
- 对单个系数$\beta_{j}$的假设检验，其t统计量为$t_{j}=\frac{\hat{\beta_{j}}}{\hat{\sigma} \sqrt{v_{j}}} \sim t_{N-p-1}$，且服从自由度为$N-p-1$分布，$v_{j}$是$({\bf{X}^{T}X})^{-1}$上的第$j$个元素
- t分布会收敛于正态分布，F统计量可以用于检验多个参数的约束，包括整个回归是否显著；以及用拉格朗日乘子进行多重约束检验

### 诊断和解决问题

诊断可以验证模型假设，帮助我们在解释结果和进⾏统计推断时避免得出错误结论。诊断⽅法包括拟合优度度量和对误差项假设的各种检验，包括残差与正态分布的匹配程度。诊断还能评估残差⽅差是否确实恒定，还是表现出异⽅差性（本节稍后会介绍）。诊断还会检验误差是否条件不相关，还是表现出序列相关性，即⼀个误差值是否有助于预测后续的误差值。

除了进⾏以下诊断测试外，你还应始终对残差进⾏可视化检查。这有助于检测它们是否反映了系统性模式，⽽不是随机噪声；随机噪声表明模型可能遗漏了⼀个或多个驱动结果的因素。

#### 拟合优度

拟合优度指标⽤于评估模型对结果变量变动的解释程度。它们有助于评估模型设定的质量，例如，在不同模型设计之间进⾏选择时。不同的拟合优度指标衡量拟合程度的⽅式也不同。在这⾥，我们将重点关注样本内指标；在下⼀节重点介绍预测模型时，我们将使⽤样本外测试和交叉验证。

常用的拟合优度度量指标包括：

- 调整后的$R^{2}$：

    $$R^{2}=1-\frac{RSS}{TSS}$$

    其中RSS为残差平方和，TSS为所有观测值$y_i$距离均值$\bar{y}$之差的平方和

    $$\begin{aligned} RSS=&\sum\limits_{i=1}^{n}(y_{i}-\hat{y}_{i})^{2} \\ TSS=&\sum\limits_{i=1}^{n}(y_{i}-\bar{y}_{i})^{2} \end{aligned}$$

    当$R^{2} \to 1$则说明模型可以完美解释数据，残差趋近于0；若为0则说明模型和均值预测一样差；若为负数则说明模型完全不合适或拟合极差。

    但是上述的计算式是单调不减的，即只要向回归模型里加变量，$R^{2}$永远不会下降(即使这个变量毫无用处)，这意味着其鼓励过拟合。因此调整后的$R^{2}$如下：

    $$\bar{R}^{2}=1-(1-R^{2})\frac{n-1}{n-k-1} \ (n为样本数量，k为自变量个数)$$

    其改进点在于加了一个惩罚项：

    - 新增变量必须显著降低 RSS，调整后$R^{2}$才会上升
    - 如果新变量没用，调整后的$R^{2}$会下降

- 赤池信息准则(AIC)：

    $$AIC=-2log(\mathcal{L}^{*})+2k\ (\mathcal{L}^{*}是最大化似然函数的值，k是参数数量)$$

- 贝叶斯信息准则(BIC)：

    $$-2log(\mathcal{L}^{*})+log(N)k \ (N是样本量)$$

第二三两种指标都会对模型的复杂性进⾏惩罚。BIC 施加的惩罚更重，因此相对于 AIC 可能会导致⽋拟合，反之亦然。从概念上讲，AIC 旨在找到最能描述未知数据⽣成过程的模型，⽽ BIC 则试图在候选模型集中找到最佳模型。在实践中，当⽬标是样本内拟合时，可以联合使⽤这两个标准来指导模型选择；否则，基于泛化误差估计的交叉验证和选择⽅法会是更好的选择。

#### 异⽅差性

⾼斯-⻢尔可夫定理的假设 5 要求残差的协⽅差形式为$\Sigma=\sigma^{2}\mathbf{I}$，即⼀个对⻆矩阵，其对⻆线上的元素等于误差项的恒定⽅差。残差⽅差不恒定，⽽是随观测值的不同⽽变化时，就会出现异⽅差性。诊断⾸先要对残差进⾏⽬视检查。如果（本应随机的）残差中存在系统性模式，则表明需要进⾏统计检验，以检验误差是同⽅差的原假设，并对⽐各种备择假设。这些检验包括布罗施-帕⽢检验和怀特检验。

#### 序列相关

序列相关是指线性回归产⽣的连续残差是相关的，这违反了⾼斯-⻢尔可夫定理的第四个假设。正向序列相关意味着标准误被低估，t 统计量将被夸⼤，如果忽略这⼀点，将导致错误的发现。不过，在计算标准误时，有⼀些程序可以校正序列相关。

#### 多重共线性

当两个或多个⾃变量⾼度相关时，就会出现多重共线性。这会带来⼏个挑战：

- 很难确定是哪些因素在影响因变量。
- 单个的 p 值可能具有误导性，即使某个变量实际上很重要，其 p 值也可能很⾼。
- 回归系数的置信区间会过宽，甚⾄可能包含零。这使得确定⾃变量对结果的影响变得复杂。

没有正式的或基于理论的解决⽅案可以纠正多重共线性。相反，可以尝试移除⼀个或多个相关的输⼊变量，或者增加样本量。

<div style="text-align: center;">
<img src="/assets/images/LLM学习/机器学习与金融量化/OLS.png" alt="描述文字" width="880" height="530">
</div>

## 构建线性因子模型

算法交易策略使⽤因⼦模型来量化资产回报与驱动这些回报的主要⻛险来源之间的关系。每种因⼦⻛险都带有溢价，⽽总资产回报可以预期为这些⻛险溢价的加权平均值。因⼦模型在整个投资组合管理流程中都有多种实际应⽤，从组合构建、资产选择到⻛险管理和绩效评估。随着共同⻛险因
⼦如今变得可交易，因⼦模型的重要性与⽇俱增。

- 通过数量少得多的因⼦来概括众多资产的回报，从⽽减少了在优化投资组合时估算协⽅差矩阵所需的数据量
- 通过估算⼀项资产或⼀个投资组合对这些因⼦的敞⼝，可以管理由此产⽣的⻛险
- 被代理时，可以通过建⽴适当的对冲来进⾏⻛险管理
- 允许评估新的阿尔法因⼦所带来的增量信号内容
- 可以帮助评估基⾦经理相对于基准的业绩表现，究竟是源于其卓越的选股能⼒和择时能⼒，还是可以由投资组合对已知回报驱动因素的倾向性来解释

### 从资本资产定价模型到法⻢-弗伦奇因⼦模型

[资本资产定价模型](/collections/llm-learning/2025-08-07-machine_learning_for_trade_algo_p2/#资本资产定价模型capm)的内容在之前的部分有讲，在此不再赘述。

1993 年，法玛-弗伦奇三因⼦模型在 CAPM 的单⼀⻛险来源基础上，增加了公司的相对规模和价值因⼦。2015 年，五因⼦模型进⼀步扩展，将公司的盈利能⼒和投资⽔平也纳⼊其中，因为在这期间的研究已证明这两个因⼦具有显著影响。此外，许多因⼦模型还包含⼀个价格动量因⼦。

法玛-弗伦奇⻛险因⼦是通过计算多元化投资组合的收益差来得出的，这些投资组合根据反映特定⻛险因⼦的指标⽽具有⾼值或低值。这些收益是通过以下⽅式获得的：⾸先根据这些指标对股票进⾏排序，然后做多⾼于某⼀特定百分位的股票，同时做空低于某⼀特定百分位的股票。与⻛险因⼦相关的指标定义如下：

- 规模：市值(ME)
- 价值：账面价值(BE)除以市值(ME)
- 经营性盈利能力(OP)：收⼊-销售成本/资产
- 投资：投资/资产

此外，还有⼀些⽆监督学习技术，可⽤于数据驱动的⻛险因⼦发现，这些技术运⽤了因⼦分析和主成分分析。

#### 获取风险因子

具体来说，我们将使⽤五个法⻢-弗伦奇因⼦，这些因⼦是通过对股票进⾏排序得出的。⾸先，将股票分为三个市值组，然后针对其余三个公司特有因⼦中的每⼀个，再将股票分为两组。因此，这些因⼦涉及三组价值加权投资组合，它们是根据市值和账⾯市值⽐、市值和营业利润率、以及市值和投资⽔平进⾏3×2排序形成的。计算出的⻛险因⼦值即为这些投资组合（PF）的平均回报。

<div style="text-align: center;">
<img src="/assets/images/LLM学习/机器学习与金融量化/法马弗伦奇.png" alt="描述文字" width="780" height="330">
</div>

#### 法⻢-弗伦奇回归

在已知⻛险因⼦和投资组合回报数据的情况下，估算投资组合对这些回报的敞⼝(exposure)是很有⽤的，这能帮助我们了解这些回报在多⼤程度上驱动了投资组合的回报。了解市场为特定因⼦敞⼝所⽀付的溢价，即承担这种⻛险的价值，也同样重要。只要我们知道或可以假定某个投资组合的因⼦敞⼝，⻛险溢价就能让我们估算出该投资组合的回报。

> **敞口和风险溢价**  
> **敞口**：量化金融中用来衡量投资组合或资产对某一风险因子的敏感度或依赖程度的指标。数学上，它对应于多因子模型中的因子载荷（factor loading），即投资组合收益对某个风险因子收益变动的回归系数。  
> **风险溢价**：投资者为了补偿承担特定风险而要求获得的额外预期收益。  
{: .prompt-info }

因⼦模型是针对特定时期内的多只股票进⾏估算的。在这类横截⾯回归中，很可能会出现推断问题，因为经典线性回归的基本假设可能不成⽴。潜在的违规情况包括测量误差、由异⽅差性和序列相关性引起的残差协变以及多重共线性。为了解决由残差相关性引起的推断问题，Fama 和 MacBeth 提出了⼀种两步法，⽤于对回报与因⼦进⾏横截⾯回归。两阶段 Fama-Macbeth 回归旨在估算市场为特定⻛险因⼦敞⼝所提供的溢价。这两个阶段包括：

1. $N$时间序列回归，对每个资产或投资组合，⽤其超额收益对因⼦进⾏回归，以估计因⼦载荷：$$\bf{r}_{i}=\boldsymbol{\beta}_{i}+\boldsymbol{\epsilon_{i}}$$

2. $T$横截⾯回归，对每个时间周期，估计⻛险溢价：$$N \times (M+1)=N \times (M+1)(M+1)+1 \times \boldsymbol{\lambda}_{t}$$

现在，我们可以将因⼦⻛险溢价计算为其时间均值，并得到⼀个 t 统计量来评估其各⾃的显著性：

$$t=\frac{\lambda_{j}}{\frac{\sigma(\lambda_{j})}{\sqrt{T}}}$$

如果我们有⼀个关于已交易⻛险因⼦的⾮常⼤且具有代表性的数据样本，我们可以使⽤样本均值作为⻛险溢价的估计。然⽽，我们通常没有⾜够⻓的历史数据，并且围绕样本均值的误差幅度可能相当⼤。Fama-Macbeth ⽅法论利⽤因⼦与其他资产的协⽅差来确定因⼦溢价。与第⼀矩相⽐，资产收益的第⼆矩更容易估计，并且获取更细粒度的数据可以显著改善估计结果，但这对于均值估计⽽⾔并⾮如此。

### 如何防止过拟合

⼀种控制过拟合的常⽤技术是正则化，它通过在误差函数中增加⼀个惩罚项来抑制系数达到较⼤的值。换⾔之，对系数的⼤⼩施加约束可以减轻其对样本外预测的潜在负⾯影响。由于过拟合是⼀个普遍存在的问题，我们将在所有模型中遇到正则化⽅法。本节中，我们将介绍收缩⽅法，这些⽅法旨在从两个⽅⾯改进我们⽬前为⽌讨论过的线性模型：

- **预测准确性**：最⼩⼆乘估计的偏差较低但⽅差较⾼，这表明通过收缩或将某些系数设为零，可以降低泛化误差，从⽽以略⾼的偏差换取模型⽅差的降低。
- **可解释性**：⼤量的预测变量可能会使结果的整体情况变得复杂，难以解释或传达。牺牲⼀些细节，将模型限制在影响最强的⼀⼩部分参数上，可能是更好的选择。

收缩模型通过对回归系数的⼤⼩施加惩罚来对其进⾏限制。它们通过在⽬标函数中添加⼀个惩罚项$S(\boldsymbol{\beta})$来实现这⼀⽬标。这个惩罚项意味着收缩模型的系数不仅要最⼩化残差平⽅和(RSS)，还要加上⼀个与系数(绝对)⼤⼩正相关的惩罚。

增加的惩罚项将线性回归系数转化为⼀个约束最⼩化问题的解，该问题通常采⽤以下拉格朗⽇形式：

$$\hat{\boldsymbol{\beta}}^{(S)} = \arg\min_{\boldsymbol{\beta}} \sum_{i=1}^N \left[ \left(y_i - \beta_0 - \sum_{j=1}^p \beta_j x_{ij} \right)^2 + \lambda S(\boldsymbol{\beta}) \right] $$

正则化参数$\lambda$决定了惩罚效应的⼤⼩，即正则化的强度。⼀旦$\lambda$为正，系数就会与⽆约束的最⼩⼆乘参数不同，这意味着估计是有偏的。你应该通过交叉验证⾃适应地选择超参数$\lambda$，以最⼩化预期预测误差的估计值。

收缩模型的不同之处在于它们如何计算惩罚项，即$S$的函数形式。最常⻅的版本是岭回归(ridge regression)，它使⽤系数的平⽅和；lasso 模型，它基于系数绝对值的总和来计算惩罚项；弹性⽹络回归(Elastic net regression)则结合了上述两种⽅法。

## 用线性模型预测收益

### 准备模型特征和远期回报

为给我们的预测模型准备数据，我们需要：

- 选择一个股票池和一个时间范围
- 构建特征并转换我们将用作特征的阿尔法因子
- 计算我们旨在预测的远期回报
- 对数据进行清洗

### 创建投资范围

确定投资的时间片段、每日元数；然后进行数据清洗，包括去除数据不足2年的股票代码，清理行业名称等，并预计使用21天滚动平均美元交易额为模型筛选流动性最强的股票。

### 因子选择和计算

使⽤ TA-Lib 创建⼀些动量和波动率因⼦，具体内容不在此赘述。

### ⽣成⽬标远期回报

该部分测试不同前瞻期的预测效果，⽬标是通过信息系数（IC）来衡量，找出能产⽣最佳预测准确率的持有期。更具体地说，我们将时间跨度为$t$的回报向后平移$t$天，将其⽤作远期回报。

### 分类变量的虚拟编码

我们需要将任何分类变量转换为数值格式，以便线性回归能够处理它。为此，我们将使⽤虚拟编码，它会为每个类别⽔平创建单独的列，并⽤ 1 来标记该⽔平在原始分类列中的存在，否则标记为 0。pandas 的 `get_dummies()` 函数可以⾃动进⾏虚拟编码。如此处所示，它能检测并正确转换对象类型的列。

当将所有类别转换为虚拟变量并使⽤截距项（通常都会这么做）来估计模型时，你会⽆意中造成多重共线性：此时矩阵包含了冗余信息，不再是满秩矩阵，⽽是变成了奇异矩阵。要避免这种情况很简单，只需删除其中⼀个新⽣成的指示列即可。被删除的类别⽔平的系数现在将被截距项捕获（截距项始终为 1，包括当所有剩余的类别虚拟变量都为 0 时）。

### 进⾏线性回归

我们将使⽤ 63 个交易⽇（即 3 个⽉）的数据来训练模型，然后预测接下来 10 天的单⽇回报率。这样，从 2015 年开始的 3 年时间⾥，我们可以使⽤⼤约 75 个 10 ⽇滚动窗⼝。交叉验证循环会遍历由 TimeSeriesCV 提供的训练和测试索引，选择特征和结果，训练模型，并预测测试特征的回报率。我们还会计算实际值与预测值之间的均⽅根误差（RMSE）和斯⽪尔曼等级相关系数。而转向其它更好的方法后，结果也得到了改善。

# 从模型到策略回测的ML4T工作流

## 如何回测机器学习驱动策略

ML4T ⼯作流旨在回测⼀种利⽤机器学习来⽣成交易信号、选择头⼨和调整头⼨规模或优化交易执⾏的交易策略。它着眼于特定的投资领域和投资期限，包含以下步骤：

- 获取并准备市场数据、基本⾯数据和另类数据
- 构建具有预测能⼒的阿尔法因⼦和特征
- 设计、调整和评估⽤于⽣成交易信号的机器学习模型
- 根据这些信号决定交易，例如，通过应⽤规则
- 在投资组合的背景下确定单个头⼨的规模
- 使⽤历史市场数据模拟由此触发的交易
- 评估由此产⽣的头⼨会有怎样的表现

<div style="text-align: center;">
<img src="/assets/images/LLM学习/机器学习与金融量化/ML4T工作流.png" alt="描述文字" width="880" height="530">
</div>

### 回测陷阱及规避方法

在万变的市场中，预测本身具有普遍的不确定性；此外，⼀些实施层⾯的问题也可能导致结果出现偏差，增加将样本内表现误认为样本外规律的⻛险。

#### 确保数据准确性

- **前视偏差：仅使用时间点数据**

    - **问题描述**：当我们使⽤历史信息来开发或评估交易规则，⽽这些信息在当时尚未可知或⽆法获取时，就会出现前视偏差。由此产⽣的业绩衡量指标将具有误导性，并且在策略实盘执⾏时，由于数据可⽤性不同，这些指标也⽆法代表未来表现。
    - **解决⽅案**：仔细验证进⼊回测的所有数据的时间戳。我们需要确保结论仅基于时间点（point-in-time）数据，这些数据不会⽆意中包含来⾃未来的信息。⾼质量的数据提供商会确保满⾜这些标准。当⽆法获得时间点数据时，我们需要对报告的延迟做出（保守的）假设。
- **幸存者偏差：追踪历史投资范围**

    - **问题描述**：当回测数据只包含当前活跃的证券，⽽忽略了那些因破产、退市或收购等原因随时间消失的资产时，就会产⽣幸存者偏差。那些不再属于投资范围的证券通常表现不佳，若未能将这些情况纳⼊考量，会使回测结果出现正向偏差。
    - **解决方案**：验证数据集包含了历史上所有可⽤的证券，⽽不仅仅是运⾏测试时仍然存在的证券。从某种程度上说，这是确保数据真正具有“时点性”（point-in-time）的另⼀种⽅式。
- **离群值控制：不要排除真实极端情况**

    - **问题描述**：数据准备通常包括对离群值的⼀些处理，例如对极端值进⾏缩尾（winsorizing）或削峰（clipping）。其挑战在于，要识别出那些真正不能代表分析期间情况的离群值，⽽不是那些当时市场环境中不可或缺的极端值。许多市场模型都假设数据呈正态分布，但正如肥尾分布所揭示的那样，极端值出现的频率其实更⾼。
    - **解决方案**：仔细分析离群值，考虑其发⽣的概率，并根据这⼀现实情况调整策略参数。
- **样本期：力求代表相关的未来情景**

    - **问题描述**：如果样本数据不能反映当前（以及可能的未来）环境，那么回测将⽆法得出具有代表性且能泛化到未来的结果。选择不当的样本数据可能缺乏相关的市场机制特征（例如，在波动性或交易量⽅⾯），未能包含⾜够的数据点，或者包含了过多或过少的极端历史事件。
    - **解决方案**：使⽤包含重要市场现象的样本期，或⽣成能反映相关市场特征的合成数据。

#### 确保模拟准确性

- **按市值计价表现：持续追踪风险**

    - **问题描述**：⼀个策略需要始终满⾜投资⽬标和约束条件。如果在回测期间表现良好，但随着时间的推移会导致⽆法接受的亏损或波动，那么这个策略（显然）是不切实际的。投资组合经理需要定期（甚⾄可能实时）追踪并报告其头⼨的价值，这被称为“按市价计价”（mark to market）。
    - **解决⽅案**：包括绘制策略表现随时间变化的图表，或计算（滚动的）⻛险指标，例如⻛险价值（VaR）或索提诺⽐率。
- **交易成本：假设真实交易环境**

    - **问题描述**：市场并不允许所有交易都能在任何时候或以⽬标价格执⾏。如果回测假设的交易实际上可能⽆法成交，或者成交条件不如预期，那么回测结果就会产⽣偏差。实际操作中的缺陷包括：策略假设可以进⾏卖空，但可能没有对⼿⽅；或者策略低估了⼤规模交易或交易流动性较差资产时对市场的影响（滑点）；⼜或者低估了经纪商佣⾦所产⽣的成本。
    - **解决方案**：包括将交易范围限制在流动性强的资产中，和/或为交易和滑点成本设定切合实际的参数。这也能防⽌因信号衰减快、投资组合换⼿率⾼⽽不稳定的因⼦得出误导性结论。
- **决策时机：正确安排信号和交易顺序**

    - **问题描述**：与前视偏差类似，模拟可能会对接收信号和根据信号进⾏交易的时间做出不切实际的假设。例如，信号可能是根据收盘价计算的，⽽交易只能在下⼀个开盘时进⾏，届时的价格可能已经⼤不相同。当我们使⽤收盘价来评估表现时，回测结果将⽆法代表真实的未来结果。
    - **解决方案**：仔细编排信号到达、交易执⾏和绩效评估的顺序。

#### 确保统计数据正确性

验证回测有效性（包括已发表的研究成果）时，最突出的挑战是因多重测试⽽发现虚假模式。基于同⼀数据对不同候选策略进⾏测试并从中选择其⼀，会导致选择出现偏差。这是因为，积极的结果更有可能是由绩效指标本身的随机性造成的。换⾔之，策略对测试样本产⽣了过拟合，得出了具有欺骗性的积极结果，⽽这些结果不太可能泛化到未来实时交易中遇到的数据。只有当试验次数被报告出来，以便评估选择偏差的⻛险时，回测表现才具有参考价值。

此外，回测过拟合的⻛险不仅源于运⾏⼤量测试，也会影响那些基于“哪些⽅法有效、哪些⽆效”的先验知识⽽设计的策略。由于这些⻛险包含了他⼈基于相同数据运⾏回测的知识，因此在实践中，回测过拟合很难避免。

因此优先进⾏那些可以⽤投资或经济理论来证明合理性的测试，⽽不是随意的“数据挖掘”；同时，也意味着要在多种背景和场景下进⾏测试，甚⾄可能包括在合成数据上进⾏测试。

#### 回测的最优停⽌策略

除了将回测限制在那些有理论依据⽽⾮纯粹数据挖掘的策略上，⼀个重要的问题是何时停⽌进⾏额外的测试。

回答这个问题的⼀种⽅法依赖于最优停⽌理论中的“秘书问题”解法，将此规则直接应⽤于回测场景，可以得出以下建议：随机测试 （约 37%）的合理策略并记录其表现。然后，继续测试，直到某个策略的表现优于之前测试过的所有策略。此规则适⽤于测试多种备选⽅案，其⽬标是在尽快选出接近最优⽅案的同时，将假阳性的⻛险降⾄最低。

### 回测引擎的工作原理

简单来说，回测引擎会遍历历史价格（及其他数据），将当前值传递给你的算法，接收返回的订单，并跟踪由此产⽣的头⼨及其价值。

#### 向量化回测与事件驱动回测

- **向量化回测**：评估策略最基本的⽅法。它将代表⽬标头⼨规模的信号向量与投资期内的收益向量相乘，从⽽计算出当期业绩。
- **事件驱动回测**：事件驱动的回测引擎明确地模拟了交易环境的时间维度，并为模拟施加了更多的结构性约束。这包括使⽤历史⽇历来定义何时可以进⾏交易以及何时可以获取报价。强制使⽤时间戳也有助于避免前瞻性偏差和上⼀节提到的其他执⾏错误（但并不能完全保证）。事件驱动系统旨在更紧密地捕捉策略遇到的⾏为和约束，理想情况下，它可以随时转换为⼀个能够提交真实订单的实盘交易引擎。

#### 关键实现要点

要实现逼真的模拟，既可以通过⼀个⽀持端到端流程所有步骤的单⼀平台来满⾜需求，也可以通过多个各司其职的专业⼯具来达成。

- **数据获取：格式、频率、时机**

    该流程的第⼀步与数据源有关。传统上，算法交易策略侧重于市场数据；如今，数据源更加多样化。另⼀个⽅⾯是可以使⽤的数据源的频率，以及不同频率的数据源是否可以组合使⽤。按计算复杂性、内存和存储要求的升序排列，常⻅的选项包括⽇度、分钟和逐笔（tick）频率。中间频率也是可⾏的。算法策略往往在更⾼频率下表现更好。最后，数据摄取还应解决时间点（point-in-time）约束问题，以避免前视偏差。使⽤交易⽇历有助于将数据限制在合法的⽇期和时间内；在摄取数据之前，需要进⾏调整以反映公司⾏为（如股票拆分和分红）或在特定时间披露并影响价格的重述。

- **因子工程：内置因子与库**

    为了⽅便构建⽤于机器学习模型的阿尔法因⼦，许多回测引擎都包含了适⽤于⼤量标准转换（如移动平均线和各种技术指标）的计算⼯具。内置因⼦⼯程的⼀个关键优势是，可以轻松地将回测流程转换为实盘交易引擎，并对输⼊数据应⽤相同的计算。

- **机器学习模型、预测、信号**

    的机器学习⼯作流可以嵌⼊到⼀个端到端平台中，该平台将模型设计和评估部分整合到回测流程中。虽然⽅便，但这种做法的成本也很⾼，因为当⽬标或许只是微调交易规则时，模型训练却成了回测的⼀部分。与因⼦⼯程类似，可以将这些⽅⾯解耦，使⽤通⽤库来设计、训练和评估机器学习模型，并将相关的预测结果作为输⼊提供给回测器。本书将主要采⽤这种⽅法，因为它能使阐述更加简洁，减少重复。

- **交易规则执行**

    ⼀个真实的策略模拟需要忠实地再现交易环境。这包括能够接⼊相关交易所，能够使⽤各种订单类型，以及对交易成本的核算。成本包括经纪商佣⾦、买卖价差和滑点，滑点即⽬标执⾏价格与最终成交价格之间的差额。确保交易执⾏时存在反映流动性和交易时间的延迟也同样重要。

- **性能评估**

    回测平台需要为性能评估提供便利。它可以提供源⾃其交易记录的标准指标，也可以输出指标，以便与 pyfolio 这类适⽤于此⽬的的库⼀同使⽤。