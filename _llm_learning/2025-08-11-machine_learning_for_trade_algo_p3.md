---
layout: post
title: "机器学习与算法交易(三): 机器学习与因子分析交易流程"
date: 2025-08-11
categories: [人工智能, 机器学习, 金融分析]
tags: [综述笔记, 金融量化]
published: true
mermaid: true
math: true
toc: true
---

# 机器学习流程

## 为任务匹配算法

不同算法的假设空间⼤⼩差异显著。⼀⽅⾯，这种限制使得成功的搜索成为可能；另⼀⽅⾯，它也意味着⼀种归纳偏⻅，当算法从训练样本泛化到新数据时，可能会导致性能不佳。因此，关键的挑战在于如何选择⼀个模型，其假设空间既要⼤到⾜以包含学习问题的解决⽅案，⼜要⼩到⾜以在给定训练数据规模的情况下确保可靠的学习和泛化。有了信息量更⼤的数据，拥有更⼤假设空间的模型成功的机会也更⼤。

## 机器学习的工作流程

1. 界定问题，确定目标指标，定义成功标准
2. 获取、清洗并验证数据
3. 理解你的数据并生成信息丰富的特征
4. 选择一个或多个适合个性化数据的机器学习方法
5. 训练、测试并调整模型、
6. 使用训练好的模型来解决最初的问题

### 构建问题：从目标到目标

任何机器学习项⽬的起点都是它最终旨在解决的⽤例。有时，这个⽬标是为了识别变量之间的关联甚⾄因果关系⽽进⾏统计推断。然⽽，最常⻅的⽬标是预测结果以产⽣交易信号。我们根据输出的性质来区分预测任务：连续的输出变量构成回归问题，分类变量意味着分类问题，⽽有序分类变量的特殊情况则代表排序问题。

你通常可以⽤不同的⽅式来构建⼀个给定的问题。⼿头的任务可能是如何有效地结合多个阿尔法因⼦。你可以将这个任务构建成⼀个旨在预测回报的回归问题，⼀个旨在预测未来价格⾛势⽅向的⼆元分类问题，或者⼀个旨在将股票分配到不同表现类别（如回报率五分位数）的多类别问题。

### 预测与推断

#### 因果推断：相关性不等于因果性

因果推断旨在识别某些输⼊值意味着某些输出值的关系。关于两个或多个变量之间关系的统计推断会产⽣相关性的度量。只有在满⾜其他⼏个条件时，相关性才能被解释为因果关系：例如，当排除了其他解释或反向因果关系时。

要满⾜这些条件，需要⼀个实验环境，其中所有相关的⽬标变量都可以被完全控制，以分离出因果关系。但是这些条件很少能得到满⾜，因此推断性结论需要谨慎对待。这同样适⽤于预测模型的性能，因为预测模型也依赖于特征和输出之间的统计关联，⽽这种关联可能会随着模型之外的其他因素⽽改变。

#### 回归：常⽤的损失函数和误差指标

回归问题旨在预测⼀个连续变量。均⽅根误差（RMSE）是最常⽤的损失函数和误差指标，这不仅因为它可微。该损失函数是对称的，但在计算中，较⼤的误差权重更⾼。使⽤平⽅根的好处在于，我们可以⽤⽬标变量的单位来衡量误差。当⽬标呈指数级增⻓时，适合使⽤对数误差均⽅根（RMSLE）。绝对误差均值（MAE）和绝对误差中位数（MedAE）是对称的，但不会给较⼤的误差赋予更多权重；MedAE 对异常值具有稳健性。

<div style="text-align: center;">
<img src="/assets/images/LLM学习/机器学习与金融量化/六种损失函数.png" alt="描述文字" width="880" height="510">
</div>

#### 分类：理解混淆矩阵、ROC与F1曲线

**混淆矩阵**即一个四元标签组：[假阳性，假阴性，真阳性，真阴性]

受试者⼯作特征（ROC）曲线使我们能够根据分类器的性能对其进⾏可视化、⽐较和选择。它计算了将所有预测得分⽤作阈值以产⽣类别预测时，所得到的真阳性率（TPR）和假阳性率（FPR）对。它将这些点对在⼀个单位边⻓的正⽅形内进⾏可视化。随机预测（加权以考虑类别不平衡）平均会产⽣相等的 TPR 和 FPR，这些点会出现在对⻆线上，这就成了基准情况。由于表现不佳的分类器可以通过重新标记预测结果来获益，因此这个基准也成了最低标准。

**曲线下⾯积（AUC）**定义为 ROC 图下⽅的⾯积，其值在 0.5 到最⼤值 1 之间变化。它是⼀个汇总性指标，衡量分类器的得分在根据类别归属对数据点进⾏排序⽅⾯的表现。更具体地说，分类器的 AUC 有⼀个重要的统计特性，即它代表了分类器将⼀个随机选择的正例排在⼀个随机选择的负例之前的概率，这等同于 Wilcoxon 秩和检验（Fawcett 2006）。此外，AUC 还有⼀个优点，即它对类别不平衡不敏感。

**召回率（Recall）**衡量的是，在给定阈值下，分类器预测为正例的样本占所有实际正例样本的⽐例。这个概念源于信息检索领域，⽤于衡量搜索引擎成功识别出的相关⽂档所占的份额。相⽐之下，精确率（Precision）衡量的是，在所有被预测为正例的样本中，预测正确的⽐例。召回率通常会随着阈值的降低⽽提⾼，但精确率可能会随之下降。精确率-召回率曲线（Precision-recall curves）将所有可⾏的组合可视化，以便在“漏掉⼤量相关案例”和“产⽣低质量预测”的成本与收益之间进⾏权衡，从⽽优化阈值。**F1 分数（F1 score）**是给定阈值下精确率和召回率的调和平均数，可⽤于从数值上优化阈值，同时还能考虑到这两个指标应占的相对权重。

### 特征分析与提取

**系统性的探索性分析**也是成功预测模型中通常最重要的单⼀因素的基础：**特征⼯程**。特征⼯程旨在提取数据中包含的信息，⽽这些信息在原始形式下不⼀定能被算法直接获取。特征⼯程得益于领域专业知识、统计学和信息论的应⽤，以及创造⼒。

同时**也可以使用信息论评估特征**，特征与结果之间的互信息（MI）是衡量这两个变量之间相互依赖性的指标。它将相关性的概念扩展到了⾮线性关系。更具体地说，它量化了通过⼀个随机变量获得的关于另⼀个随机变量的信息。

$$I(X,Y)=\int_{X} \int_{Y} p(x,y) log(\frac{p(x,y)}{p(x)p(y)})$$

### 机器学习的算法选择

#### 偏差-方差均衡与学习曲线

在优化机器学习算法的过程中，需要考虑偏差-方差权衡，即不能欠拟合，也需要尽可能避免过拟合。⾼偏差模型⽆论在样本内还是样本外，都会有较⾼但相似的训练误差。⽽过拟合模型的训练误差会⾮常低，但测试误差会⾼得多。

#### 如何用交叉验证选择模型

交叉验证（CV）是⼀种常⽤的模型选择策略。其主要思想是将数据进⾏⼀次或多次拆分。这样⼀来，每个数据⼦集都有⼀次机会被⽤作验证集，⽽其余部分则⽤作训练集：⼀部分数据（训练样本）⽤于训练算法，剩余部分（验证样本）则⽤于评估算法的预测性能。然后，交叉验证会选择估计误差或⻛险最⼩的算法。但交叉验证的⼀个关键假设是数据独⽴同分布（IID）。

<div style="text-align: center;">
<img src="/assets/images/LLM学习/机器学习与金融量化/三次划分法.png" alt="描述文字" width="880" height="430">
</div>

#### 验证曲线：绘制超参数的影响

验证曲线将单个超参数对模型交叉验证性能的影响可视化。这有助于确定模型对于给定数据集是⽋拟合还是过拟合。

#### 学习曲线：诊断偏差-⽅差权衡

学习曲线有助于确定模型的交叉验证性能是否会因额外数据⽽受益，以及预测误差是由偏差还是⽅差主导。如果训练得分和交叉验证得分趋于收敛，那么更多的数据不太可能提升模型性能。此时，重要的是评估模型性能是否达到由⼈类基准所确定的预期。如果未达到预期，那么您应该修改模型的超参数设置以更好地捕捉特征与结果之间的关系，或者选择另⼀种具有更⾼复杂性捕捉能⼒的算法。

# 线性模型：从风险因子到收益预测

## 从推断到预测

**1. 线性回归模型的基本假设**

- **线性关系假设**：输出变量$y$是输入变量的线性组合再加上一个随机误差项 $\varepsilon$。
- **随机误差的意义**：误差允许每个观测值与理想的线性关系有偏离，原因可能包括：
    - 重要变量缺失
    - 测量误差
    - 数据收集问题
- **误差的统计假设（基线模型）**：
    1. 误差服从相同分布（方差一致）
    2. 各观测的误差相互独立
    3. 独立同分布（i.i.d.）意味着误差的协方差矩阵为常数 $\sigma^2$ 乘以单位矩阵 III

这些假设保证了 OLS（普通最小二乘）不仅是无偏估计，还在所有线性无偏估计中具有最小方差（有效性）。

**2. 现实中的挑战**

在实际金融数据中，特别是 **面板数据**（同一资产在不同时间的重复观测），上述假设常常被破坏：

- 时间维度上存在相关性（序列相关）
- 横截面维度上存在相关性（不同资产之间相关）
- 两者同时存在

当误差不再是单位矩阵的倍数时，需要更复杂的模型假设和估计方法。

**3. 解决方法**

3.1 改进线性模型的估计方法

- 针对违背 i.i.d. 假设的情况，使用更复杂的误差协方差结构（如 Newey-West 标准误）来获得稳健估计。

3.2 有偏估计 + 降低方差（收缩方法）

- 思路：引入**正则化惩罚项**，限制系数的大小，从而降低模型复杂度。
- 原理：惩罚项与系数的绝对值大小正相关，系数越大，模型对输入的波动反应越强，复杂度也越高。
- 优势：如果正则化强度（惩罚系数）选择得当，从**偏差-方差权衡**的角度可以得到更优的预测性能。
- 常见方法：Lasso、Ridge、Elastic Net 等。

## 基准模型：多元线性回归

最基础的多元线性回归模型可以用下述公式表示：

$$\bf{y}=\bf{X} \boldsymbol{\beta} + \boldsymbol{\epsilon}$$

训练时则可以用多种方法进行训练：普通最小二乘法，最大似然估计和随机梯度下降法。

### 高斯-马尔可夫定理

⾼斯-⻢尔可夫定理（GMT）定义了普通最⼩⼆乘法（OLS）要对模型参数产⽣⽆偏估计所需满⾜的假设，并确保这些估计在所有针对横截⾯数据的线性模型中具有最低的标准误。

该定理的核心内容为：

$$\begin{aligned} & 对于给定的多元回归模型： y_{i}=\sum\limits_{k=1}\beta_{k}x_{ik}+\beta_{0}+\epsilon_{i}  \\ & 假设条件包括：  \\ &  1.线性关系成立：模型在参数上线性 \\ & 2.随机抽样：(x_{i1},\cdots,x_{ik},y_{i})来自总体的随机样本 \\ & 3. 无完全共线性：解释变量间不存在精确的线性依赖 \\ & 4. 零条件均值：\mathbb{E}[\epsilon_{i} \| {\bf{X}}_{i}]=0 \to 不存在与任何解释变量相关的遗漏变量 \\ & 5. 同方差性：Var(\epsilon_{i} \| {\bf{X}}_{i})=\sigma^{2} \to 误差方差对所有观测恒定 \end{aligned}$$

该定理可以这样简单理解：第一点反映了输入输出间整体呈现可信的线性关系，第二点反映了样本的覆盖度，第三点反映了输入输出的随机性与可信度，第四点反映了模型囊括了所有输入变量，第五点反映了推断的准确性。

即使正态性假设不成⽴，在正态性假设下使⽤的检验统计量也近似有效。更具体地说，在满⾜⾼斯-⻢尔可夫定理的 1-5 条假设时，检验统计量的以下分布特征近似成⽴；⽽在满⾜正态性假设时，这些特征则精确成⽴：

- 参数服从多元正态分布：$\hat{\beta} \sim N(\beta,({\bf{X}^{T}X})^{-1}\sigma)$
- 满足高斯-马尔可夫定理时参数估计无偏，为$\hat{\sigma}=\frac{1}{N-p-1}\sum\limits_{i=1}^{N}(y_{i}-\hat{y}_{i})^{2}$
- 对单个系数$\beta_{j}$的假设检验，其t统计量为$t_{j}=\frac{\hat{\beta_{j}}}{\hat{\sigma} \sqrt{v_{j}}} \sim t_{N-p-1}$，且服从自由度为$N-p-1$分布，$v_{j}$是$({\bf{X}^{T}X})^{-1}$上的第$j$个元素
- t分布会收敛于正态分布，F统计量可以用于检验多个参数的约束，包括整个回归是否显著；以及用拉格朗日乘子进行多重约束检验

### 诊断和解决问题

诊断可以验证模型假设，帮助我们在解释结果和进⾏统计推断时避免得出错误结论。诊断⽅法包括拟合优度度量和对误差项假设的各种检验，包括残差与正态分布的匹配程度。诊断还能评估残差⽅差是否确实恒定，还是表现出异⽅差性（本节稍后会介绍）。诊断还会检验误差是否条件不相关，还是表现出序列相关性，即⼀个误差值是否有助于预测后续的误差值。

除了进⾏以下诊断测试外，你还应始终对残差进⾏可视化检查。这有助于检测它们是否反映了系统性模式，⽽不是随机噪声；随机噪声表明模型可能遗漏了⼀个或多个驱动结果的因素。

#### 拟合优度

拟合优度指标⽤于评估模型对结果变量变动的解释程度。它们有助于评估模型设定的质量，例如，在不同模型设计之间进⾏选择时。不同的拟合优度指标衡量拟合程度的⽅式也不同。在这⾥，我们将重点关注样本内指标；在下⼀节重点介绍预测模型时，我们将使⽤样本外测试和交叉验证。

常用的拟合优度度量指标包括：

- 调整后的$R^{2}$：

    $$R^{2}=1-\frac{RSS}{TSS}$$

    其中RSS为残差平方和，TSS为所有观测值$y_i$距离均值$\bar{y}$之差的平方和

    $$\begin{aligned} RSS=&\sum\limits_{i=1}^{n}(y_{i}-\hat{y}_{i})^{2} \\ TSS=&\sum\limits_{i=1}^{n}(y_{i}-\bar{y}_{i})^{2} \end{aligned}$$

    当$R^{2} \to 1$则说明模型可以完美解释数据，残差趋近于0；若为0则说明模型和均值预测一样差；若为负数则说明模型完全不合适或拟合极差。

    但是上述的计算式是单调不减的，即只要向回归模型里加变量，$R^{2}$永远不会下降(即使这个变量毫无用处)，这意味着其鼓励过拟合。因此调整后的$R^{2}$如下：

    $$\bar{R}^{2}=1-(1-R^{2})\frac{n-1}{n-k-1} \ (n为样本数量，k为自变量个数)$$

    其改进点在于加了一个惩罚项：

    - 新增变量必须显著降低 RSS，调整后$R^{2}$才会上升
    - 如果新变量没用，调整后的$R^{2}$会下降

- 赤池信息准则(AIC)：

    $$AIC=-2log(\mathcal{L}^{*})+2k\ (\mathcal{L}^{*}是最大化似然函数的值，k是参数数量)$$

- 贝叶斯信息准则(BIC)：

    $$-2log(\mathcal{L}^{*})+log(N)k \ (N是样本量)$$

第二三两种指标都会对模型的复杂性进⾏惩罚。BIC 施加的惩罚更重，因此相对于 AIC 可能会导致⽋拟合，反之亦然。从概念上讲，AIC 旨在找到最能描述未知数据⽣成过程的模型，⽽ BIC 则试图在候选模型集中找到最佳模型。在实践中，当⽬标是样本内拟合时，可以联合使⽤这两个标准来指导模型选择；否则，基于泛化误差估计的交叉验证和选择⽅法会是更好的选择。

#### 异⽅差性

⾼斯-⻢尔可夫定理的假设 5 要求残差的协⽅差形式为$\Sigma=\sigma^{2}\mathbf{I}$，即⼀个对⻆矩阵，其对⻆线上的元素等于误差项的恒定⽅差。残差⽅差不恒定，⽽是随观测值的不同⽽变化时，就会出现异⽅差性。诊断⾸先要对残差进⾏⽬视检查。如果（本应随机的）残差中存在系统性模式，则表明需要进⾏统计检验，以检验误差是同⽅差的原假设，并对⽐各种备择假设。这些检验包括布罗施-帕⽢检验和怀特检验。

#### 序列相关

序列相关是指线性回归产⽣的连续残差是相关的，这违反了⾼斯-⻢尔可夫定理的第四个假设。正向序列相关意味着标准误被低估，t 统计量将被夸⼤，如果忽略这⼀点，将导致错误的发现。不过，在计算标准误时，有⼀些程序可以校正序列相关。

#### 多重共线性

当两个或多个⾃变量⾼度相关时，就会出现多重共线性。这会带来⼏个挑战：

- 很难确定是哪些因素在影响因变量。
- 单个的 p 值可能具有误导性，即使某个变量实际上很重要，其 p 值也可能很⾼。
- 回归系数的置信区间会过宽，甚⾄可能包含零。这使得确定⾃变量对结果的影响变得复杂。

没有正式的或基于理论的解决⽅案可以纠正多重共线性。相反，可以尝试移除⼀个或多个相关的输⼊变量，或者增加样本量。

<div style="text-align: center;">
<img src="/assets/images/LLM学习/机器学习与金融量化/OLS.png" alt="描述文字" width="880" height="530">
</div>

## 构建线性因子模型

算法交易策略使⽤因⼦模型来量化资产回报与驱动这些回报的主要⻛险来源之间的关系。每种因⼦⻛险都带有溢价，⽽总资产回报可以预期为这些⻛险溢价的加权平均值。因⼦模型在整个投资组合管理流程中都有多种实际应⽤，从组合构建、资产选择到⻛险管理和绩效评估。随着共同⻛险因
⼦如今变得可交易，因⼦模型的重要性与⽇俱增。

- 通过数量少得多的因⼦来概括众多资产的回报，从⽽减少了在优化投资组合时估算协⽅差矩阵所需的数据量
- 通过估算⼀项资产或⼀个投资组合对这些因⼦的敞⼝，可以管理由此产⽣的⻛险
- 被代理时，可以通过建⽴适当的对冲来进⾏⻛险管理
- 允许评估新的阿尔法因⼦所带来的增量信号内容
- 可以帮助评估基⾦经理相对于基准的业绩表现，究竟是源于其卓越的选股能⼒和择时能⼒，还是可以由投资组合对已知回报驱动因素的倾向性来解释

### 从资本资产定价模型到法⻢-弗伦奇因⼦模型

[资本资产定价模型](/collections/llm-learning/2025-08-07-machine_learning_for_trade_algo_p2/#资本资产定价模型capm)的内容在之前的部分有讲，在此不再赘述。

1993 年，法玛-弗伦奇三因⼦模型在 CAPM 的单⼀⻛险来源基础上，增加了公司的相对规模和价值因⼦。2015 年，五因⼦模型进⼀步扩展，将公司的盈利能⼒和投资⽔平也纳⼊其中，因为在这期间的研究已证明这两个因⼦具有显著影响。此外，许多因⼦模型还包含⼀个价格动量因⼦。

法玛-弗伦奇⻛险因⼦是通过计算多元化投资组合的收益差来得出的，这些投资组合根据反映特定⻛险因⼦的指标⽽具有⾼值或低值。这些收益是通过以下⽅式获得的：⾸先根据这些指标对股票进⾏排序，然后做多⾼于某⼀特定百分位的股票，同时做空低于某⼀特定百分位的股票。与⻛险因⼦相关的指标定义如下：

- 规模：市值(ME)
- 价值：账面价值(BE)除以市值(ME)
- 经营性盈利能力(OP)：收⼊-销售成本/资产
- 投资：投资/资产

此外，还有⼀些⽆监督学习技术，可⽤于数据驱动的⻛险因⼦发现，这些技术运⽤了因⼦分析和主成分分析。

#### 获取风险因子

具体来说，我们将使⽤五个法⻢-弗伦奇因⼦，这些因⼦是通过对股票进⾏排序得出的。⾸先，将股票分为三个市值组，然后针对其余三个公司特有因⼦中的每⼀个，再将股票分为两组。因此，这些因⼦涉及三组价值加权投资组合，它们是根据市值和账⾯市值⽐、市值和营业利润率、以及市值和投资⽔平进⾏3×2排序形成的。计算出的⻛险因⼦值即为这些投资组合（PF）的平均回报。

<div style="text-align: center;">
<img src="/assets/images/LLM学习/机器学习与金融量化/法马弗伦奇.png" alt="描述文字" width="780" height="330">
</div>

#### 法⻢-弗伦奇回归

在已知⻛险因⼦和投资组合回报数据的情况下，估算投资组合对这些回报的敞⼝(exposure)是很有⽤的，这能帮助我们了解这些回报在多⼤程度上驱动了投资组合的回报。了解市场为特定因⼦敞⼝所⽀付的溢价，即承担这种⻛险的价值，也同样重要。只要我们知道或可以假定某个投资组合的因⼦敞⼝，⻛险溢价就能让我们估算出该投资组合的回报。

> **敞口和风险溢价**  
> **敞口**：量化金融中用来衡量投资组合或资产对某一风险因子的敏感度或依赖程度的指标。数学上，它对应于多因子模型中的因子载荷（factor loading），即投资组合收益对某个风险因子收益变动的回归系数。  
> **风险溢价**：投资者为了补偿承担特定风险而要求获得的额外预期收益。  
{: .prompt-info}

因⼦模型是针对特定时期内的多只股票进⾏估算的。在这类横截⾯回归中，很可能会出现推断问题，因为经典线性回归的基本假设可能不成⽴。潜在的违规情况包括测量误差、由异⽅差性和序列相关性引起的残差协变以及多重共线性。为了解决由残差相关性引起的推断问题，Fama 和 MacBeth 提出了⼀种两步法，⽤于对回报与因⼦进⾏横截⾯回归。两阶段 Fama-Macbeth 回归旨在估算市场为特定⻛险因⼦敞⼝所提供的溢价。这两个阶段包括：

1. $N$时间序列回归，对每个资产或投资组合，⽤其超额收益对因⼦进⾏回归，以估计因⼦载荷：$$\bf{r}_{i}=\boldsymbol{\beta}_{i}+\boldsymbol{\epsilon_{i}}$$

2. $T$横截⾯回归，对每个时间周期，估计⻛险溢价：$$N \times (M+1)=N \times (M+1)(M+1)+1 \times \boldsymbol{\lambda}_{t}$$

现在，我们可以将因⼦⻛险溢价计算为其时间均值，并得到⼀个 t 统计量来评估其各⾃的显著性：

$$t=\frac{\lambda_{j}}{\frac{\sigma(\lambda_{j})}{\sqrt{T}}}$$

如果我们有⼀个关于已交易⻛险因⼦的⾮常⼤且具有代表性的数据样本，我们可以使⽤样本均值作为⻛险溢价的估计。然⽽，我们通常没有⾜够⻓的历史数据，并且围绕样本均值的误差幅度可能相当⼤。Fama-Macbeth ⽅法论利⽤因⼦与其他资产的协⽅差来确定因⼦溢价。与第⼀矩相⽐，资产收益的第⼆矩更容易估计，并且获取更细粒度的数据可以显著改善估计结果，但这对于均值估计⽽⾔并⾮如此。

### 如何防止过拟合

⼀种控制过拟合的常⽤技术是正则化，它通过在误差函数中增加⼀个惩罚项来抑制系数达到较⼤的值。换⾔之，对系数的⼤⼩施加约束可以减轻其对样本外预测的潜在负⾯影响。由于过拟合是⼀个普遍存在的问题，我们将在所有模型中遇到正则化⽅法。本节中，我们将介绍收缩⽅法，这些⽅法旨在从两个⽅⾯改进我们⽬前为⽌讨论过的线性模型：

- **预测准确性**：最⼩⼆乘估计的偏差较低但⽅差较⾼，这表明通过收缩或将某些系数设为零，可以降低泛化误差，从⽽以略⾼的偏差换取模型⽅差的降低。
- **可解释性**：⼤量的预测变量可能会使结果的整体情况变得复杂，难以解释或传达。牺牲⼀些细节，将模型限制在影响最强的⼀⼩部分参数上，可能是更好的选择。

收缩模型通过对回归系数的⼤⼩施加惩罚来对其进⾏限制。它们通过在⽬标函数中添加⼀个惩罚项$S(\boldsymbol{\beta})$来实现这⼀⽬标。这个惩罚项意味着收缩模型的系数不仅要最⼩化残差平⽅和(RSS)，还要加上⼀个与系数(绝对)⼤⼩正相关的惩罚。

增加的惩罚项将线性回归系数转化为⼀个约束最⼩化问题的解，该问题通常采⽤以下拉格朗⽇形式：

$$\hat{\boldsymbol{\beta}}^{(S)} = \arg\min_{\boldsymbol{\beta}} \sum_{i=1}^N \left[ \left(y_i - \beta_0 - \sum_{j=1}^p \beta_j x_{ij} \right)^2 + \lambda S(\boldsymbol{\beta}) \right] $$

正则化参数$\lambda$决定了惩罚效应的⼤⼩，即正则化的强度。⼀旦$\lambda$为正，系数就会与⽆约束的最⼩⼆乘参数不同，这意味着估计是有偏的。你应该通过交叉验证⾃适应地选择超参数$\lambda$，以最⼩化预期预测误差的估计值。

收缩模型的不同之处在于它们如何计算惩罚项，即$S$的函数形式。最常⻅的版本是岭回归(ridge regression)，它使⽤系数的平⽅和；lasso 模型，它基于系数绝对值的总和来计算惩罚项；弹性⽹络回归(Elastic net regression)则结合了上述两种⽅法。

## 用线性模型预测收益

### 准备模型特征和远期回报

为给我们的预测模型准备数据，我们需要：

- 选择一个股票池和一个时间范围
- 构建特征并转换我们将用作特征的阿尔法因子
- 计算我们旨在预测的远期回报
- 对数据进行清洗

### 创建投资范围

确定投资的时间片段、每日元数；然后进行数据清洗，包括去除数据不足2年的股票代码，清理行业名称等，并预计使用21天滚动平均美元交易额为模型筛选流动性最强的股票。

### 因子选择和计算

使⽤ TA-Lib 创建⼀些动量和波动率因⼦，具体内容不在此赘述。

### ⽣成⽬标远期回报

该部分测试不同前瞻期的预测效果，⽬标是通过信息系数（IC）来衡量，找出能产⽣最佳预测准确率的持有期。更具体地说，我们将时间跨度为$t$的回报向后平移$t$天，将其⽤作远期回报。

### 分类变量的虚拟编码

我们需要将任何分类变量转换为数值格式，以便线性回归能够处理它。为此，我们将使⽤虚拟编码，它会为每个类别⽔平创建单独的列，并⽤ 1 来标记该⽔平在原始分类列中的存在，否则标记为 0。pandas 的 `get_dummies()` 函数可以⾃动进⾏虚拟编码。如此处所示，它能检测并正确转换对象类型的列。

当将所有类别转换为虚拟变量并使⽤截距项（通常都会这么做）来估计模型时，你会⽆意中造成多重共线性：此时矩阵包含了冗余信息，不再是满秩矩阵，⽽是变成了奇异矩阵。要避免这种情况很简单，只需删除其中⼀个新⽣成的指示列即可。被删除的类别⽔平的系数现在将被截距项捕获（截距项始终为 1，包括当所有剩余的类别虚拟变量都为 0 时）。

### 进⾏线性回归

我们将使⽤ 63 个交易⽇（即 3 个⽉）的数据来训练模型，然后预测接下来 10 天的单⽇回报率。这样，从 2015 年开始的 3 年时间⾥，我们可以使⽤⼤约 75 个 10 ⽇滚动窗⼝。交叉验证循环会遍历由 TimeSeriesCV 提供的训练和测试索引，选择特征和结果，训练模型，并预测测试特征的回报率。我们还会计算实际值与预测值之间的均⽅根误差（RMSE）和斯⽪尔曼等级相关系数。而转向其它更好的方法后，结果也得到了改善。